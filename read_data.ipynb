{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9531fdc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Stock Market Dataset Loader ===\n",
      "Loading NASDAQ, NYSE, and S&P500 datasets\n",
      "\n",
      "=== SYSTEM INFO ===\n",
      "Python version: 3.11.7\n",
      "NumPy version: 1.26.4\n",
      "Pandas version: 2.2.3\n",
      "Working directory: e:\\Fintech\\practicum\\StockMixer\n",
      "\n",
      "Contents of dataset folder: ['NASDAQ', 'NYSE', 'read.py', 'SP500']\n",
      "\n",
      "Processing NASDAQ files in: dataset\\NASDAQ\n",
      "\n",
      "Attempting to load: dataset\\NASDAQ\\eod_data.pkl\n",
      "Found dataset\\NASDAQ\\eod_data.pkl (25547565 bytes)\n",
      "Successfully loaded eod_data.pkl\n",
      "Data type: <class 'numpy.ndarray'>\n",
      "dtype: float32\n",
      "data size: 6386850\n",
      "data.ndim 3\n",
      "Array shape: (1026, 1245, 5)\n",
      "First 5 elements:\n",
      "[[[0.270533 0.269522 0.267237 0.263333 0.275333]\n",
      "  [0.271109 0.269741 0.26782  0.263982 0.271219]\n",
      "  [0.271822 0.270097 0.268485 0.264723 0.272316]\n",
      "  ...\n",
      "  [0.948882 0.967983 0.969176 0.962736 0.951735]\n",
      "  [0.949321 0.96472  0.968531 0.964939 0.962841]\n",
      "  [0.952475 0.962416 0.969258 0.967535 0.976964]]\n",
      "\n",
      " [[0.23873  0.237522 0.239888 0.240502 0.248031]\n",
      "  [0.242457 0.238787 0.240177 0.241316 0.252493]\n",
      "  [0.246929 0.240493 0.240549 0.24192  0.253806]\n",
      "  ...\n",
      "  [0.966404 0.954462 0.927362 0.921172 0.952756]\n",
      "  [0.965354 0.955906 0.92979  0.922353 0.951444]\n",
      "  [0.961942 0.955512 0.932874 0.923185 0.937008]]\n",
      "\n",
      " [[0.424556 0.424768 0.429769 0.442628 0.445018]\n",
      "  [0.429273 0.425433 0.428402 0.44199  0.439414]\n",
      "  [0.431209 0.425488 0.427924 0.441073 0.427177]\n",
      "  ...\n",
      "  [0.966126 0.974762 0.976926 0.966988 0.958976]\n",
      "  [0.963255 0.971562 0.974963 0.96943  0.960735]\n",
      "  [0.961348 0.968384 0.973116 0.971692 0.961019]]\n",
      "\n",
      " [[0.650667 0.648412 0.634492 0.631473 0.667839]\n",
      "  [0.651282 0.650551 0.636067 0.632694 0.655824]\n",
      "  [0.65433  0.651536 0.637949 0.634184 0.662125]\n",
      "  ...\n",
      "  [0.843956 0.827326 0.809817 0.8384   0.827839]\n",
      "  [0.842784 0.831502 0.80989  0.835592 0.840293]\n",
      "  [0.837949 0.835018 0.811722 0.832857 0.838828]]\n",
      "\n",
      " [[0.766565 0.761693 0.75933  0.750061 0.788157]\n",
      "  [0.772027 0.763939 0.761417 0.75206  0.782159]\n",
      "  [0.777106 0.766386 0.763037 0.754166 0.782159]\n",
      "  ...\n",
      "  [0.956202 0.972575 0.974158 0.970172 0.942573]\n",
      "  [0.953088 0.967534 0.972779 0.970244 0.949592]\n",
      "  [0.953573 0.963757 0.972275 0.970772 0.961205]]]\n",
      "\n",
      "Data type: float32\n",
      "data size: 6386850\n",
      "data.ndim 3\n",
      "\n",
      "Attempting to load: dataset\\NASDAQ\\gt_data.pkl\n",
      "Found dataset\\NASDAQ\\gt_data.pkl (5109643 bytes)\n",
      "Successfully loaded gt_data.pkl\n",
      "Data type: <class 'numpy.ndarray'>\n",
      "dtype: float32\n",
      "data size: 1277370\n",
      "data.ndim 2\n",
      "Array shape: (1026, 1245)\n",
      "First 5 elements:\n",
      "[[ 0.         -0.01494191  0.00404479 ...  0.01878863  0.01166917\n",
      "   0.01466807]\n",
      " [ 0.          0.01798964  0.00520015 ... -0.03328856 -0.00137708\n",
      "  -0.01517267]\n",
      " [ 0.         -0.01259275 -0.02784841 ... -0.00371412  0.0018343\n",
      "   0.00029556]\n",
      " [ 0.         -0.01799084  0.00960774 ... -0.00615627  0.01504396\n",
      "  -0.0017434 ]\n",
      " [ 0.         -0.00761018  0.         ... -0.01546205  0.00744662\n",
      "   0.01222948]]\n",
      "\n",
      "Data type: float32\n",
      "data size: 1277370\n",
      "data.ndim 2\n",
      "\n",
      "Attempting to load: dataset\\NASDAQ\\mask_data.pkl\n",
      "Found dataset\\NASDAQ\\mask_data.pkl (5109643 bytes)\n",
      "Successfully loaded mask_data.pkl\n",
      "Data type: <class 'numpy.ndarray'>\n",
      "dtype: float32\n",
      "data size: 1277370\n",
      "data.ndim 2\n",
      "Array shape: (1026, 1245)\n",
      "First 5 elements:\n",
      "[[1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]]\n",
      "\n",
      "Data type: float32\n",
      "data size: 1277370\n",
      "data.ndim 2\n",
      "\n",
      "Attempting to load: dataset\\NASDAQ\\price_data.pkl\n",
      "Found dataset\\NASDAQ\\price_data.pkl (5109643 bytes)\n",
      "Successfully loaded price_data.pkl\n",
      "Data type: <class 'numpy.ndarray'>\n",
      "dtype: float32\n",
      "data size: 1277370\n",
      "data.ndim 2\n",
      "Array shape: (1026, 1245)\n",
      "First 5 elements:\n",
      "[[0.275333 0.271219 0.272316 ... 0.951735 0.962841 0.976964]\n",
      " [0.248031 0.252493 0.253806 ... 0.952756 0.951444 0.937008]\n",
      " [0.445018 0.439414 0.427177 ... 0.958976 0.960735 0.961019]\n",
      " [0.667839 0.655824 0.662125 ... 0.827839 0.840293 0.838828]\n",
      " [0.788157 0.782159 0.782159 ... 0.942573 0.949592 0.961205]]\n",
      "\n",
      "Data type: float32\n",
      "data size: 1277370\n",
      "data.ndim 2\n",
      "\n",
      "Reading SP500 data...\n",
      "\n",
      "Processing SP500 files in: dataset\\SP500\n",
      "\n",
      "Attempting to load: dataset\\SP500\\SP500.npy\n",
      "Found dataset\\SP500\\SP500.npy (47893088 bytes)\n",
      "Loading SP500.npy with numpy...\n",
      "Loaded SP500.npy with shape (474, 2526, 5) and dtype float64\n",
      "Successfully loaded SP500.npy\n",
      "Data type: <class 'numpy.ndarray'>\n",
      "dtype: float64\n",
      "data size: 5986620\n",
      "data.ndim 3\n",
      "Array shape: (474, 2526, 5)\n",
      "First 5 elements:\n",
      "[[[0.06249355 0.06326962 0.06242409 0.02836958 0.06281907]\n",
      "  [0.06211543 0.06375049 0.06270169 0.04036122 0.06359782]\n",
      "  [0.06350761 0.0636818  0.06341302 0.02706721 0.06337285]\n",
      "  ...\n",
      "  [0.69567908 0.70331629 0.69386514 0.07277307 0.70045864]\n",
      "  [0.69329    0.69546774 0.66365937 0.05412213 0.67353124]\n",
      "  [0.66415731 0.68320536 0.65770844 0.06917312 0.68095528]]\n",
      "\n",
      " [[0.26974629 0.26492781 0.27185171 0.06881749 0.27028316]\n",
      "  [0.27084731 0.26641827 0.27281967 0.10823899 0.27109352]\n",
      "  [0.27285783 0.26786213 0.27548156 0.06775735 0.27361999]\n",
      "  ...\n",
      "  [0.87343232 0.85756869 0.87532671 0.08900596 0.87348654]\n",
      "  [0.87745337 0.87452258 0.88713584 0.07099012 0.89341214]\n",
      "  [0.89640977 0.87498837 0.89352434 0.10202212 0.89055205]]\n",
      "\n",
      " [[0.13297438 0.13255131 0.13263751 0.04577648 0.13177053]\n",
      "  [0.13207218 0.13551995 0.13290138 0.06079727 0.13506116]\n",
      "  [0.1355064  0.13514526 0.13252024 0.06236091 0.13209086]\n",
      "  ...\n",
      "  [0.68102444 0.67615867 0.67292135 0.02451036 0.67990681]\n",
      "  [0.67892897 0.67512108 0.66893401 0.01763096 0.67967384]\n",
      "  [0.67485448 0.68088544 0.67714324 0.02674193 0.68188703]]\n",
      "\n",
      " [[0.29883545 0.2978702  0.29598458 0.12913342 0.29448531]\n",
      "  [0.29579746 0.29501377 0.29294259 0.11624269 0.29206572]\n",
      "  [0.29539241 0.29461288 0.29076251 0.12017797 0.28929327]\n",
      "  ...\n",
      "  [0.79296203 0.79959907 0.79101602 0.06227474 0.80169367]\n",
      "  [0.79640503 0.79163116 0.7752991  0.06435772 0.78450449]\n",
      "  [0.79564557 0.81062386 0.79126953 0.10006075 0.80910369]]\n",
      "\n",
      " [[0.20770458 0.2042578  0.20804061 0.15149867 0.20745733]\n",
      "  [0.20775244 0.2032926  0.20729133 0.26475548 0.20620514]\n",
      "  [0.20691499 0.20466256 0.20675958 0.22188979 0.2047695 ]\n",
      "  ...\n",
      "  [0.77472487 0.75721957 0.77046403 0.20443888 0.76407725]\n",
      "  [0.76399747 0.74970812 0.75692874 0.13346026 0.76435637]\n",
      "  [0.76938107 0.76578187 0.76977921 0.20648425 0.77935076]]]\n",
      "\n",
      "Data type: float64\n",
      "data size: 5986620\n",
      "data.ndim 3\n",
      "\n",
      "\n",
      "=== DATASET SUMMARY ===\n",
      "\n",
      "--- NASDAQ Dataset ---\n",
      "\n",
      "Successfully loaded files (4):\n",
      "  eod_data.pkl: <class 'numpy.ndarray'>\n",
      "    Shape: (1026, 1245, 5)\n",
      "    Data type: float32\n",
      "  gt_data.pkl: <class 'numpy.ndarray'>\n",
      "    Shape: (1026, 1245)\n",
      "    Data type: float32\n",
      "  mask_data.pkl: <class 'numpy.ndarray'>\n",
      "    Shape: (1026, 1245)\n",
      "    Data type: float32\n",
      "  price_data.pkl: <class 'numpy.ndarray'>\n",
      "    Shape: (1026, 1245)\n",
      "    Data type: float32\n",
      "\n",
      "--- NYSE Dataset ---\n",
      "\n",
      "Successfully loaded files (0):\n",
      "\n",
      "--- SP500 Dataset ---\n",
      "\n",
      "Successfully loaded files (1):\n",
      "  SP500.npy: <class 'numpy.ndarray'>\n",
      "    Shape: (474, 2526, 5)\n",
      "    Data type: float64\n",
      "\n",
      "Processing complete!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "from typing import Dict, Any, Union\n",
    "\n",
    "def verify_file(file_path: str) -> bool:\n",
    "    \"\"\"Verify that a file exists and has content.\"\"\"\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"File not found: {file_path}\")\n",
    "        return False\n",
    "    file_size = os.path.getsize(file_path)\n",
    "    if file_size == 0:\n",
    "        print(f\"Warning: {file_path} is empty (0 bytes)\")\n",
    "        return False\n",
    "    print(f\"Found {file_path} ({file_size} bytes)\")\n",
    "    return True\n",
    "\n",
    "def load_pickle_file(file_path: str) -> Any:\n",
    "    \"\"\"Safely load a pickle file with multiple fallback methods.\"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'rb') as f:\n",
    "            # First try standard pickle load\n",
    "            return pickle.load(f)\n",
    "    except pickle.UnpicklingError:\n",
    "        try:\n",
    "            # Try with pandas if standard pickle fails\n",
    "            return pd.read_pickle(file_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Pandas pickle load failed: {str(e)}\")\n",
    "            try:\n",
    "                # Try with different protocol versions\n",
    "                with open(file_path, 'rb') as f:\n",
    "                    return pickle.load(f, encoding='latin1')\n",
    "            except Exception as e:\n",
    "                print(f\"All pickle loading methods failed: {str(e)}\")\n",
    "                return None\n",
    "    except EOFError:\n",
    "        print(\"EOFError: Ran out of input - file may be corrupted or incomplete\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error loading pickle: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def load_npy_file(file_path: str) -> np.ndarray:\n",
    "    \"\"\"Safely load a numpy .npy file with proper pickle settings.\"\"\"\n",
    "    try:\n",
    "        # Enable allow_pickle for object arrays\n",
    "        data = np.load(file_path, allow_pickle=True)\n",
    "        # Handle 0-dimensional arrays\n",
    "        if data.ndim == 0:\n",
    "            return np.array([data.item()])  # Convert to 1D array\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading .npy file: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def read_exchange_data(exchange: str, data_summary: Dict[str, Dict[str, Any]]) -> None:\n",
    "    \"\"\"Read data for a specific exchange (NASDAQ/NYSE).\"\"\"\n",
    "    exchange_path = os.path.join('dataset', exchange)\n",
    "    if not os.path.exists(exchange_path):\n",
    "        print(f\"\\nERROR: {exchange} folder not found at: {exchange_path}\")\n",
    "        return\n",
    "    \n",
    "    print(f\"\\nProcessing {exchange} files in: {exchange_path}\")\n",
    "    file_types = ['eod_data.pkl', 'gt_data.pkl', 'mask_data.pkl', 'price_data.pkl']\n",
    "    \n",
    "    for file_type in file_types:\n",
    "        file_path = os.path.join(exchange_path, file_type)\n",
    "        print(f\"\\nAttempting to load: {file_path}\")\n",
    "        \n",
    "        if not verify_file(file_path):\n",
    "            data_summary[exchange][file_type] = None\n",
    "            continue\n",
    "            \n",
    "        data = load_pickle_file(file_path)\n",
    "        data_summary[exchange][file_type] = data\n",
    "        \n",
    "        if data is not None:\n",
    "            print(f\"Successfully loaded {file_type}\")\n",
    "            print_sample_data(data)\n",
    "\n",
    "def read_sp500_data(data_summary: Dict[str, Dict[str, Any]]) -> None:\n",
    "    \"\"\"Read S&P500 data files.\"\"\"\n",
    "    sp500_path = os.path.join('dataset', 'SP500')\n",
    "    if not os.path.exists(sp500_path):\n",
    "        print(f\"\\nERROR: SP500 folder not found at: {sp500_path}\")\n",
    "        return\n",
    "    \n",
    "    print(f\"\\nProcessing SP500 files in: {sp500_path}\")\n",
    "    sp500_files = ['SP500.npy']\n",
    "    # sp500_files = ['baseline_data_sp500.npy']\n",
    "    \n",
    "    for file in sp500_files:\n",
    "        file_path = os.path.join(sp500_path, file)\n",
    "        if not os.path.exists(file_path):\n",
    "            continue\n",
    "            \n",
    "        print(f\"\\nAttempting to load: {file_path}\")\n",
    "        if not verify_file(file_path):\n",
    "            data_summary['SP500'][file] = None\n",
    "            continue\n",
    "        print(f\"Loading {file} with numpy...\")  \n",
    "        data = load_npy_file(file_path)\n",
    "        print(f\"Loaded {file} with shape {data.shape} and dtype {data.dtype}\")\n",
    "        data_summary['SP500'][file] = data\n",
    "        \n",
    "        if data is not None:\n",
    "            print(f\"Successfully loaded {file}\")\n",
    "            print_sample_data(data)\n",
    "\n",
    "def print_sample_data(data: Any) -> None:\n",
    "    \"\"\"Print sample data from loaded file, handling various types safely.\"\"\"\n",
    "    print(f\"Data type: {type(data)}\")\n",
    "    print(\"dtype:\", data.dtype)\n",
    "    print(\"data size:\", data.size)\n",
    "    print(\"data.ndim\", data.ndim)\n",
    "    \n",
    "    try:\n",
    "        if isinstance(data, np.ndarray):\n",
    "            print(f\"Array shape: {data.shape}\")\n",
    "            print(\"First 5 elements:\")\n",
    "            if data.size > 0:  # Check if array has elements\n",
    "                if data.ndim == 0:  # Handle 0-dimensional arrays\n",
    "                    print(np.array([data.item()]))\n",
    "                else:\n",
    "                    print(data[:5] if len(data) > 5 else data)\n",
    "                    \n",
    "                    print(\"\\nData type:\", data.dtype)\n",
    "                    print(\"data size:\", data.size)\n",
    "                    print(\"data.ndim\", data.ndim)\n",
    "            else:\n",
    "                print(\"Empty array\")\n",
    "        elif isinstance(data, pd.DataFrame):\n",
    "            print(f\"DataFrame shape: {data.shape}\")\n",
    "            print(\"First 5 rows:\")\n",
    "            print(data.head(5) if len(data) > 0 else \"Empty DataFrame\")\n",
    "        elif isinstance(data, dict):\n",
    "            print(f\"Dictionary with {len(data)} keys\")\n",
    "            print(\"First 5 items:\")\n",
    "            print(dict(list(data.items())[:5]) if len(data) > 0 else \"Empty dictionary\")\n",
    "        elif isinstance(data, list):\n",
    "            print(f\"List with {len(data)} items\")\n",
    "            print(\"First 5 items:\")\n",
    "            print(data[:5] if len(data) > 0 else \"Empty list\")\n",
    "        else:\n",
    "            print(\"Data preview:\")\n",
    "            preview = str(data)\n",
    "            print(preview[:5] + \"...\" if len(preview) > 5 else preview)\n",
    "    except Exception as e:\n",
    "        print(f\"Error while printing sample data: {str(e)}\")\n",
    "\n",
    "\n",
    "\n",
    "def generate_dataset_summary(data_summary: Dict[str, Dict[str, Any]]) -> None:\n",
    "    \"\"\"Generate comprehensive summary of loaded datasets.\"\"\"\n",
    "    print(\"\\n\\n=== DATASET SUMMARY ===\")\n",
    "    \n",
    "    for exchange, files in data_summary.items():\n",
    "        print(f\"\\n--- {exchange} Dataset ---\")\n",
    "        \n",
    "        loaded_files = [f for f, d in files.items() if d is not None]\n",
    "        missing_files = [f for f, d in files.items() if d is None]\n",
    "        \n",
    "        print(f\"\\nSuccessfully loaded files ({len(loaded_files)}):\")\n",
    "        for file in loaded_files:\n",
    "            data = files[file]\n",
    "            print(f\"  {file}: {type(data)}\")\n",
    "            if isinstance(data, np.ndarray):\n",
    "                print(f\"    Shape: {data.shape}\")\n",
    "                print(f\"    Data type: {data.dtype}\")\n",
    "            elif isinstance(data, pd.DataFrame):\n",
    "                print(f\"    Shape: {data.shape}\")\n",
    "                print(f\"    Columns: {list(data.columns)}\")\n",
    "            elif isinstance(data, dict):\n",
    "                print(f\"    Keys: {len(data)}\")\n",
    "        \n",
    "        if missing_files:\n",
    "            print(f\"\\nFailed to load files ({len(missing_files)}): {', '.join(missing_files)}\")\n",
    "\n",
    "def main():\n",
    "    print(\"=== Stock Market Dataset Loader ===\")\n",
    "    print(\"Loading NASDAQ, NYSE, and S&P500 datasets\\n\")\n",
    "    \n",
    "    # Diagnostic information\n",
    "    print(\"=== SYSTEM INFO ===\")\n",
    "    print(f\"Python version: {sys.version.split()[0]}\")\n",
    "    print(f\"NumPy version: {np.__version__}\")\n",
    "    print(f\"Pandas version: {pd.__version__}\")\n",
    "    print(f\"Working directory: {os.getcwd()}\")\n",
    "    \n",
    "    if not os.path.exists('dataset'):\n",
    "        print(\"\\nERROR: 'dataset' folder not found in current directory!\")\n",
    "        return\n",
    "    \n",
    "    print(\"\\nContents of dataset folder:\", os.listdir('dataset'))\n",
    "    \n",
    "    # Initialize data summary structure\n",
    "    data_summary = {\n",
    "        'NASDAQ': {},\n",
    "        'NYSE': {},\n",
    "        'SP500': {}\n",
    "    }\n",
    "    \n",
    "    # Read all data files\n",
    "    read_exchange_data('NASDAQ', data_summary)\n",
    "    # 0 byte for NYSE\n",
    "    # read_exchange_data('NYSE', data_summary)\n",
    "    print(\"\\nReading SP500 data...\")\n",
    "    read_sp500_data(data_summary)\n",
    "    \n",
    "    # Generate summary report\n",
    "    generate_dataset_summary(data_summary)\n",
    "    \n",
    "    print(\"\\nProcessing complete!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
